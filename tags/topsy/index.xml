<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Topsy on フリーランチなど無い - There ain&#39;t no such thing as a free lunch</title>
    <link>http://tanstaafl.0pt.jp/tags/topsy/</link>
    <description>Recent content in Topsy on フリーランチなど無い - There ain&#39;t no such thing as a free lunch</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja-jp</language>
    <lastBuildDate>Mon, 22 Nov 2010 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://tanstaafl.0pt.jp/tags/topsy/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>コメントシステムにNode.js&#43;Backtweetsを採用</title>
      <link>http://tanstaafl.0pt.jp/posts/2010/11/22/a0f229152618/</link>
      <pubDate>Mon, 22 Nov 2010 00:00:00 +0000</pubDate>
      
      <guid>http://tanstaafl.0pt.jp/posts/2010/11/22/a0f229152618/</guid>
      <description>&lt;p&gt;最近いろいろと試行錯誤を繰り返しているTwitterでのコメントシステムだが、結局Topsyは取りやめた。コメントの一部がうまく反映されないことがあるからだ。&lt;/p&gt;

&lt;p&gt;代わりに採用したのがbacktweetsだ。Topsyなどと同様に自分のサイトにリンクしているコンテンツをピックアップしてくれるBacktypeというサービスがある。Disqusにも採用されている便利検索サービスなのだが、そのBacktypeのAPIをラップしてtwitterからのリンクだけを抽出してくれるサービスがbacktweetsである。制限等はBacktypeと同じというかうまくゲートウェイだけ作って、検索等はBacktypeに乗っかっている。なのでAPIも基本的にはBacktypeへのproxyとなっている。&lt;/p&gt;

&lt;p&gt;ここで問題なのはbacktypeのAPIにJSONPが含まれていないことである。先日書いたようにJSONではブラウザのXSS対策にひっかかって他サイトのデータを取って来ることが出来ない。そこでproxyサーバを立てて自分のサーバから直接backtweetsのAPIを叩くようにした。サーバに使ったのは最近いじっていて面白いと思っているNode.jsというjavascriptの処理系だ。こいつはイベントループでIOブロックしない並列処理をガリガリかけるのが特徴なようだが今回はただのサーバとして使っている。とはいえ、たかがProxyのためにいくつもプロセスを立ち上げたくはないので、その点スケーラビリティの高いNode.jsは便利である。処理速度もGoogleのV8エンジンがベースになっているので素晴らしく早い。とはいえアプリケーションサーバ内でHTTPアクセスを繰り返しているのでページの読み込みは遅くなってしまう。&lt;/p&gt;

&lt;p&gt;対処法として&lt;/p&gt;

&lt;p&gt;Sinatraのキャッシュを使って初回のみbacktweetsのAPIを叩くようにする
Ajaxで遅延読み込みを行う
の二つを考えたが、backtweets（というかBacktype）のAPIが1日千回という制限があるのでキャッシュでアクセス回数を押さえられる１のアプローチを取った。ページがキャッシュされてないときだけSinatra側でNode.jsのproxyにアクセスしてデータを取ってくる。これなら読み込みの遅さも随分軽減出来てなかなか快適にTwitterによるコメントシステムを実装出来た。&lt;/p&gt;

&lt;p&gt;ただ、これを実装してから気付いたのだがSinatra側で読み込むのであればNode.jsのproxyはそもそも必要ない。とはいえNode.jsの（特にイベントの）勉強になったのと、せっかく作ったのにRubyで作り直すのも勿体ないのでしばらくはこのままで運用しようと思っている。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>JSONとJSONPの違い</title>
      <link>http://tanstaafl.0pt.jp/posts/2010/11/17/75eb52a3779e/</link>
      <pubDate>Wed, 17 Nov 2010 00:00:00 +0000</pubDate>
      
      <guid>http://tanstaafl.0pt.jp/posts/2010/11/17/75eb52a3779e/</guid>
      <description>&lt;p&gt;Twitter APIで取得していたコメントが消えてしまった。Twitter検索で引っかかるのは7日間だけである。これでは少し寂しいのでツイートの取得にTopsyを利用してみた。Topsyはツイッター等の発言をベースにした検索エンジンで、公開されたAPIから特定のサイトについてのツイートを抽出して取得するといったことが出来る。&lt;/p&gt;

&lt;p&gt;それでTopsyのAPIをjQueryの機能で取得してみようとしたのだがjsonを取得しようとするとリクエストは200 OKを返すのにデータが取得出来ない。jQueryが原因かと思って色々調べてみたのだが違うようだ。原因はスクリプトの実行元と異なるドメインのデータをxmlHttpRequestでは取得出来ないかららしい。何故このようにしているかというとクロスサイトスクリプティングを防止するためのようだ。しかしこの制限にも抜け道がある。それがJSONPである。&lt;/p&gt;

&lt;p&gt;JSONPはscriptタグを利用してリモートのデータを読み込む。JSONの実体がjavascriptのコードであることを利用しているのだ。そしてコールバックを実行してデータを再生する。シンプルな仕組みである。&lt;/p&gt;

&lt;p&gt;参考にしたのはここのサイトである（jQueryはJSONPの理解の妨げになるか？）。
僕は今までJSONとJSONPについて違いがよくわかっておらず、単にコールバックを指定するのがJSONPだと思っていた。しかしAjaxの処理にはデータ形式によらずコールバックを使うのだからこれでは違いにならない。scriptタグを利用したデータの読み込みこそがJSONPだったのだ。こういうことはjQueryの解説サイトにはあんまり書いていない。Ajax技術としては常識なんだろうけどjQueryでAjaxを始めた人のためにも是非啓蒙して欲しいと思う。&lt;/p&gt;

&lt;p&gt;まとめ&lt;/p&gt;

&lt;p&gt;JSONを含め通常Ajaxで使うxmlHttpRequestでは外部サイトのデータを取得出来ない(XSS対策）
JSONPはscriptタグで外部サイトを読み込むことで上記を回避している
jQueryではJSONとJSONPを同じように扱えるが両者はまったく由来の異なる技術である。&lt;/p&gt;

&lt;p&gt;JSONはただのデータ形式（javascriptのオブジェクトをtext化したもの）
JSONPはデータを読み込むための技術（javascriptコードの読み込み）&lt;/p&gt;

&lt;p&gt;Ajaxではデータの受け渡しの形式としてどちらも用いられている。&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
